# -*- coding: utf-8 -*-
"""HousingStreamlit.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10wIJjRK0oTEHq7EODsxBTNcOJpqZv1Yg
"""

# app.py

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

# -------------------------------------
# CONFIGURATION & PAGE SETUP
# -------------------------------------

st.set_page_config(
    page_title="Miami Housing Price Estimator",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("Miami Housing Price Estimator")
st.markdown("""
This application predicts housing prices based on user input using Linear Regression and Random Forest models.
It also provides model evaluation metrics and key insights from the dataset.
""")

# -------------------------------------
# LOAD MODELS AND SCALER
# -------------------------------------

@st.cache_resource
def load_models():
    # Replace with actual model files after exporting them
    lr_model = joblib.load("linear_model.pkl")         # Linear Regression
    rf_model = joblib.load("random_forest_model.pkl")  # Random Forest
    scaler = joblib.load("scaler.pkl")                 # StandardScaler
    return lr_model, rf_model, scaler

# Load models and scaler (only if exporting externally)
# lr_model, rf_model, scaler = load_models()

# -------------------------------------
# LOAD DATASET (FOR EXPLORATION & VISUALIZATION)
# -------------------------------------

@st.cache_data
def load_data():
    df = pd.read_csv("miami_housing_sample.csv")  # Replace with full CSV path
    return df

df = load_data()
feature_columns = df.drop("SALE_PRC", axis=1).columns.tolist()

# -------------------------------------
# USER INPUT SECTION
# -------------------------------------

st.sidebar.header("Input House Features")
st.sidebar.markdown("Enter the features of your property below:")

def get_user_input():
    input_data = {}
    for feature in feature_columns:
        if df[feature].dtype in [np.float64, np.int64]:
            input_data[feature] = st.sidebar.number_input(f"{feature}", value=float(df[feature].median()))
        else:
            input_data[feature] = st.sidebar.selectbox(f"{feature}", options=df[feature].unique())
    return pd.DataFrame([input_data])

user_input_df = get_user_input()

# -------------------------------------
# MODEL TRAINING AND PREDICTION (LOCAL VERSION)
# -------------------------------------

# Fit scaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df[feature_columns])
user_scaled = scaler.transform(user_input_df)

# Fit models
X = df[feature_columns]
y = df["SALE_PRC"]

lr_model = LinearRegression()
rf_model = RandomForestRegressor(random_state=42)

lr_model.fit(X_scaled, y)
rf_model.fit(X_scaled, y)

# Predictions
lr_pred = lr_model.predict(user_scaled)[0]
rf_pred = rf_model.predict(user_scaled)[0]

# Display Predictions
st.subheader("Estimated Property Price")
st.write(f"Linear Regression Prediction: ${lr_pred:,.2f}")
st.write(f"Random Forest Prediction: ${rf_pred:,.2f}")

# Confidence estimate
std_dev = df["SALE_PRC"].std()
st.write(f"Approximate Confidence Range: ±${std_dev:.2f}")

# -------------------------------------
# MODEL PERFORMANCE SECTION
# -------------------------------------

st.subheader("Model Performance Comparison")

# Evaluation split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

def get_metrics(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    st.markdown(f"**{model_name}**")
    st.write(f"MAE : {mae:.2f}")
    st.write(f"RMSE: {rmse:.2f}")
    st.write(f"R²  : {r2:.4f}")
    return pd.Series([mae, rmse, r2], index=["MAE", "RMSE", "R2"])

lr_metrics = get_metrics(y_test, lr_model.predict(X_test), "Linear Regression")
rf_metrics = get_metrics(y_test, rf_model.predict(X_test), "Random Forest")

# Display comparison
metrics_df = pd.DataFrame({"Linear Regression": lr_metrics, "Random Forest": rf_metrics})
st.bar_chart(metrics_df.T)

# -------------------------------------
# EXPLORATORY DATA ANALYSIS SECTION
# -------------------------------------

st.subheader("Data Exploration and Visual Insights")

col1, col2 = st.columns(2)

with col1:
    st.markdown("Distribution of Sale Prices")
    fig, ax = plt.subplots()
    sns.histplot(df["SALE_PRC"], bins=40, ax=ax, kde=True)
    st.pyplot(fig)

with col2:
    st.markdown("Correlation Heatmap")
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
    st.pyplot(fig)

st.markdown("Scatter Plots of Key Predictive Features")
target_corr = df.corr(numeric_only=True)["SALE_PRC"].drop("SALE_PRC").abs().sort_values(ascending=False)
top_features = target_corr.head(4).index

fig, axs = plt.subplots(2, 2, figsize=(15, 10))
axs = axs.flatten()

for i, feature in enumerate(top_features):
    sns.scatterplot(data=df, x=feature, y="SALE_PRC", ax=axs[i])
    axs[i].set_title(f"{feature} vs SALE_PRC")

plt.tight_layout()
st.pyplot(fig)

# -------------------------------------
# FOOTER
# -------------------------------------

st.markdown("---")
st.caption("Developed for academic and stakeholder presentation of housing price modeling.")