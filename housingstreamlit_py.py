# -*- coding: utf-8 -*-
"""HousingStreamlit.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10wIJjRK0oTEHq7EODsxBTNcOJpqZv1Yg
"""

# app.py


# app.py

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split



# -------------------------------------
# CONFIGURATION & PAGE SETUP
# -------------------------------------

st.set_page_config(
    page_title="Miami Housing Price Estimator",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("Miami Housing Price Estimator")
st.markdown("""
This application predicts housing prices based on user input using Linear Regression and Random Forest models.
It also provides model evaluation metrics and key insights from the dataset.
""")

# -------------------------------------
# LOAD MODELS AND SCALER
# -------------------------------------

@st.cache_resource
def load_models():
    lr_model = joblib.load("linear_model.pkl")
    rf_model = joblib.load("random_forest_model.pkl")
    scaler = joblib.load("scaler.pkl")
    return lr_model, rf_model, scaler

lr_model, rf_model, scaler = load_models()

# -------------------------------------
# LOAD DATASET (FOR EXPLORATION & FEATURE REFERENCE)
# -------------------------------------

@st.cache_data
def load_data():
    df = pd.read_csv("miami_housing_sample.csv")
    return df

df = load_data()


# Define columns for modeling
feature_columns = df.drop("SALE_PRC", axis=1).columns.tolist()

# Descriptive names for UI display
feature_labels = {
    "LND_SQFOOT": "Land Area (sq ft)",
    "TOT_LVG_AREA": "Living Area (sq ft)",
    "SPEC_FEAT_VAL": "Special Feature Value ($)",
    "RAIL_DIST": "Distance to Nearest Rail Line (ft)",
    "OCEAN_DIST": "Distance to Ocean (ft)",
    "WATER_DIST": "Distance to Water Body (ft)",
    "CNTR_DIST": "Distance to Downtown Miami (ft)",
    "SUBCNTR_DI": "Distance to Subcenter (ft)",
    "HWY_DIST": "Distance to Highway (ft)",
    "age": "Age of Structure",
    "avno60plus": "Airplane Noise > 60 dB (1=Yes)",
    "structure_quality": "Structure Quality",
    "month_sold": "Month Sold (1 = Jan)",
    "LATITUDE": "Latitude",
    "LONGITUDE": "Longitude"
}

# -------------------------------------
# USER INPUT SECTION
# -------------------------------------

st.sidebar.header("Input House Features")
st.sidebar.markdown("Enter the features of your property below:")

def get_user_input():
    input_data = {}
    for feature in feature_columns:
        label = feature_labels.get(feature, feature)
        if df[feature].dtype in [np.float64, np.int64]:
            input_data[feature] = st.sidebar.number_input(f"{label}", value=float(df[feature].median()))
        else:
            input_data[feature] = st.sidebar.selectbox(f"{label}", options=df[feature].unique())
    return pd.DataFrame([input_data])

user_input_df = get_user_input()

# -------------------------------------
# MAKE PREDICTIONS
# -------------------------------------

# Ensure the input columns match what the scaler expects
try:
    user_input_df = user_input_df[scaler.feature_names_in_]
except AttributeError:
    st.error("Scaler does not contain feature names. It may have been trained on a NumPy array. Please retrain it on a DataFrame.")
    st.stop()
except KeyError as e:
    st.error(f"Input features do not match the scaler's expected input. Missing columns: {e}")
    st.stop()

# Now safe to transform
user_scaled = scaler.transform(user_input_df)
lr_pred = lr_model.predict(user_scaled)[0]
rf_pred = rf_model.predict(user_scaled)[0]

st.subheader("Estimated Property Price")
st.write(f"Linear Regression Prediction: ${lr_pred:,.2f}")
st.write(f"Random Forest Prediction: ${rf_pred:,.2f}")

rf_test_preds = rf_model.predict(scaler.transform(df[feature_columns]))
rf_pred_std = np.std(rf_test_preds)
st.info(f"Approximate Confidence Range for Random Forest Prediction: ±${rf_pred_std:.2f}")

# -------------------------------------
# MODEL PERFORMANCE SECTION
# -------------------------------------

st.subheader("Model Performance Comparison")

X = df[feature_columns]
y = df["SALE_PRC"]
X_scaled = scaler.transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

lr_test_pred = lr_model.predict(X_test)
rf_test_pred = rf_model.predict(X_test)

def compute_metrics(y_true, y_pred):
    return {
        "MAE": mean_absolute_error(y_true, y_pred),
        "RMSE": np.sqrt(mean_squared_error(y_true, y_pred)),
        "R2": r2_score(y_true, y_pred)
    }

lr_metrics = compute_metrics(y_test, lr_test_pred)
rf_metrics = compute_metrics(y_test, rf_test_pred)

col1, col2 = st.columns(2)

with col1:
    st.markdown("**Linear Regression Metrics**")
    st.write(f"MAE : {lr_metrics['MAE']:.2f}")
    st.write(f"RMSE: {lr_metrics['RMSE']:.2f}")
    st.write(f"R²  : {lr_metrics['R2']:.4f}")

with col2:
    st.markdown("**Random Forest Metrics**")
    st.write(f"MAE : {rf_metrics['MAE']:.2f}")
    st.write(f"RMSE: {rf_metrics['RMSE']:.2f}")
    st.write(f"R²  : {rf_metrics['R2']:.4f}")

st.markdown("### Model Comparison Summary")
better_model = "Random Forest" if rf_metrics["R2"] < lr_metrics["R2"] else "Linear Regression"
st.success(f"Based on R2, the better performing model is: **{better_model}**.")

# -------------------------------------
# DATA EXPLORATION
# -------------------------------------

st.subheader("Data Exploration and Visual Insights")

col1, col2 = st.columns(2)

with col1:
    st.markdown("Distribution of Sale Prices")
    fig1, ax1 = plt.subplots()
    sns.histplot(df["SALE_PRC"], bins=40, ax=ax1, kde=True)
    st.pyplot(fig1)

with col2:
    st.markdown("Correlation Heatmap")
    fig2, ax2 = plt.subplots(figsize=(8, 6))
    sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=".2f", cmap="coolwarm", ax=ax2)
    st.pyplot(fig2)

st.markdown("Scatter Plots of Key Predictive Features")
target_corr = df.corr(numeric_only=True)["SALE_PRC"].drop("SALE_PRC").abs().sort_values(ascending=False)
top_features = target_corr.head(4).index

fig3, axs = plt.subplots(2, 2, figsize=(15, 10))
axs = axs.flatten()

for i, feature in enumerate(top_features):
    sns.scatterplot(data=df, x=feature, y="SALE_PRC", ax=axs[i])
    axs[i].set_title(f"{feature} vs SALE_PRC")

plt.tight_layout()
st.pyplot(fig3)

# -------------------------------------
# FOOTER
# -------------------------------------

st.markdown("---")
st.caption("Developed for academic and stakeholder presentation of housing price modeling.")
